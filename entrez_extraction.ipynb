{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import Entrez\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置Entrez的email\n",
    "Entrez.email = 'xc2611@nyu.edu'\n",
    "\n",
    "def search(query, start_year=None, end_year=None):\n",
    "    handle = Entrez.esearch(db='pubmed',\n",
    "                            sort='relevance',\n",
    "                            retmax='100000',\n",
    "                            retmode='xml',\n",
    "                            term=query,\n",
    "                            datetype='pdat' if start_year and end_year else 'none',\n",
    "                            mindate=start_year if start_year else '',\n",
    "                            maxdate=end_year if end_year else '')\n",
    "    results = Entrez.read(handle)\n",
    "    return results\n",
    "\n",
    "def fetch_details(id_list, max_retries=3, retry_delay=5):\n",
    "    ids = ','.join(id_list)\n",
    "    attempt = 0\n",
    "    while attempt < max_retries:\n",
    "        try:\n",
    "            handle = Entrez.efetch(db='pubmed',\n",
    "                                   retmode='xml',\n",
    "                                   id=ids)\n",
    "            results = Entrez.read(handle)\n",
    "            return results\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching details, attempt {attempt + 1}/{max_retries}: {e}\")\n",
    "            attempt += 1\n",
    "            time.sleep(retry_delay)\n",
    "    raise Exception(\"Failed to fetch details after multiple attempts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69527\n"
     ]
    }
   ],
   "source": [
    "# 搜索研究\n",
    "query = \"Crohn's disease\"\n",
    "studies = search(query)\n",
    "total_records = int(studies['Count'])\n",
    "print(total_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Too many hits. Splitting search by time periods...\n",
      "Fetching abstracts for 1950-1990...\n",
      "# of hits for 1950-1990: 11173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/myenv/lib/python3.10/site-packages/Bio/Entrez/Parser.py:1077: UserWarning: Failed to save pubmed_240101.dtd at /Users/xr/.config/biopython/Bio/Entrez/DTDs/pubmed_240101.dtd\n",
      "  warnings.warn(f\"Failed to save {filename} at {path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching abstracts for 1991-2000...\n",
      "# of hits for 1991-2000: 7265\n",
      "Fetching abstracts for 2001-2010...\n",
      "# of hits for 2001-2010: 14501\n",
      "Fetching abstracts for 2011-2015...\n",
      "# of hits for 2011-2015: 11412\n",
      "Fetching abstracts for 2016-2020...\n",
      "# of hits for 2016-2020: 13911\n",
      "Fetching abstracts for 2021-2025...\n",
      "# of hits for 2021-2025: 12423\n"
     ]
    }
   ],
   "source": [
    "# 定义时间段\n",
    "time_periods = [(1950, 1990), (1991, 2000), (2001, 2010),\n",
    "                (2011, 2015), (2016, 2020), (2021, 2025)]\n",
    "\n",
    "\n",
    "\n",
    "# 初始化数据列表\n",
    "title_list = []\n",
    "abstract_list = []\n",
    "journal_list = []\n",
    "language_list = []\n",
    "pubdate_year_list = []\n",
    "doi_list = []\n",
    "\n",
    "if total_records <= 10000:\n",
    "    print(\"Fetching all records...\")\n",
    "    id_list = studies[\"IdList\"]\n",
    "    # 直接提取所有结果\n",
    "    chunk_size = 1000  # 每批次请求的文章数量\n",
    "    for chunk_i in range(0, len(id_list), chunk_size):\n",
    "        chunk = id_list[chunk_i:chunk_i + chunk_size]\n",
    "        try:\n",
    "            papers = fetch_details(chunk)\n",
    "            for paper in papers['PubmedArticle']:\n",
    "                paper_id = paper['MedlineCitation']['PMID']\n",
    "                title_list.append(paper['MedlineCitation']['Article']['ArticleTitle'])\n",
    "                try:\n",
    "                    abstract_list.append(paper['MedlineCitation']['Article']['Abstract']['AbstractText'][0])\n",
    "                except KeyError:\n",
    "                    abstract_list.append('No Abstract')\n",
    "                journal_list.append(paper['MedlineCitation']['Article']['Journal']['Title'])\n",
    "                language_list.append(paper['MedlineCitation']['Article']['Language'][0])\n",
    "                try:\n",
    "                    pubdate_year_list.append(paper['MedlineCitation']['Article']['Journal']['JournalIssue']['PubDate']['Year'])\n",
    "                except KeyError:\n",
    "                    pubdate_year_list.append('No Data')\n",
    "                try:\n",
    "                    doi = next((elocation_id for elocation_id in paper['MedlineCitation']['Article']['ELocationID'] \n",
    "                               if elocation_id.attributes['EIdType'] == 'doi'), 'No DOI')\n",
    "                except KeyError:\n",
    "                    doi = 'No DOI'\n",
    "                doi_list.append(doi)\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching details for chunk {chunk_i}: {e}\")\n",
    "\n",
    "else:\n",
    "    print(\"Too many hits. Splitting search by time periods...\")\n",
    "    for start_year, end_year in time_periods:\n",
    "        print(f\"Fetching abstracts for {start_year}-{end_year}...\")\n",
    "        # 按时间段搜索\n",
    "        studies = search(query=query, start_year=start_year, end_year=end_year)\n",
    "        total_records = int(studies['Count'])\n",
    "        if total_records == 0:\n",
    "            continue\n",
    "\n",
    "        id_list = studies[\"IdList\"]\n",
    "        print(f\"# of hits for {start_year}-{end_year}: {total_records}\")\n",
    "\n",
    "        # 分批次提取数据\n",
    "        chunk_size = 1000  # 每批次请求的文章数量\n",
    "        for chunk_i in range(0, len(id_list), chunk_size):\n",
    "            chunk = id_list[chunk_i:chunk_i + chunk_size]\n",
    "            try:\n",
    "                papers = fetch_details(chunk)\n",
    "                for paper in papers['PubmedArticle']:\n",
    "                    paper_id = paper['MedlineCitation']['PMID']\n",
    "                    title_list.append(paper['MedlineCitation']['Article']['ArticleTitle'])\n",
    "                    try:\n",
    "                        abstract_list.append(paper['MedlineCitation']['Article']['Abstract']['AbstractText'][0])\n",
    "                    except KeyError:\n",
    "                        abstract_list.append('No Abstract')\n",
    "                    journal_list.append(paper['MedlineCitation']['Article']['Journal']['Title'])\n",
    "                    language_list.append(paper['MedlineCitation']['Article']['Language'][0])\n",
    "                    try:\n",
    "                        pubdate_year_list.append(paper['MedlineCitation']['Article']['Journal']['JournalIssue']['PubDate']['Year'])\n",
    "                    except KeyError:\n",
    "                        pubdate_year_list.append('No Data')\n",
    "                    try:\n",
    "                        doi = next((elocation_id for elocation_id in paper['MedlineCitation']['Article']['ELocationID'] \n",
    "                                   if elocation_id.attributes['EIdType'] == 'doi'), 'No DOI')\n",
    "                    except KeyError:\n",
    "                        doi = 'No DOI'\n",
    "                    doi_list.append(doi)\n",
    "            except Exception as e:\n",
    "                print(f\"Error fetching details for chunk {chunk_i}: {e}\")\n",
    "\n",
    "# 创建并保存DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Title': title_list,\n",
    "    'Abstract': abstract_list,\n",
    "    'Journal': journal_list,\n",
    "    'Language': language_list,\n",
    "    'Year': pubdate_year_list,\n",
    "    'DOI': doi_list\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Month'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.10/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Month'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMonth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mJan\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m01\u001b[39m\u001b[38;5;124m'\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      2\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMonth\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFeb\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m02\u001b[39m\u001b[38;5;124m'\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMonth\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMar\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m03\u001b[39m\u001b[38;5;124m'\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.10/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.10/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Month'"
     ]
    }
   ],
   "source": [
    "df['Month'].replace('Jan', '01', inplace=True)\n",
    "df['Month'].replace('Feb', '02', inplace=True)\n",
    "df['Month'].replace('Mar', '03', inplace=True)\n",
    "df['Month'].replace('Apr', '04', inplace=True)\n",
    "df['Month'].replace('May', '05', inplace=True)\n",
    "df['Month'].replace('Jun', '06', inplace=True)\n",
    "df['Month'].replace('Jul', '07', inplace=True)\n",
    "df['Month'].replace('Aug', '08', inplace=True)\n",
    "df['Month'].replace('Sep', '09', inplace=True)\n",
    "df['Month'].replace('Oct', '10', inplace=True)\n",
    "df['Month'].replace('Nov', '11', inplace=True)\n",
    "df['Month'].replace('Dec', '12', inplace=True)\n",
    "df['Month'].replace('No Data', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   Title  \\\n",
      "0            A simple index of Crohn's-disease activity.   \n",
      "1                                       Crohn's disease.   \n",
      "2                         Crohn's disease and pregnancy.   \n",
      "3                         Crohn's disease and pregnancy.   \n",
      "4                             Anorectal Crohn's disease.   \n",
      "...                                                  ...   \n",
      "57228  Association between inflammatory bowel disease...   \n",
      "57229  Is Occupation a Risk Factor for Developing Inf...   \n",
      "57230  Changes in the Penetration Rate of Biosimilar ...   \n",
      "57231  Transition Readiness in Youth with Inflammator...   \n",
      "57232  HIF-Dependent <i>NFATC1</i> Activation Upregul...   \n",
      "\n",
      "                                                Abstract  \\\n",
      "0                                            No Abstract   \n",
      "1                                            No Abstract   \n",
      "2      Seventy-eight pregnancies in 50 patients were ...   \n",
      "3      This paper reports the outcome of 60 pregnanci...   \n",
      "4                                            No Abstract   \n",
      "...                                                  ...   \n",
      "57228  Emerging evidence from observational studies s...   \n",
      "57229  The role of occupation is uncertain in the ons...   \n",
      "57230  Infliximab, which was approved in 2002, had it...   \n",
      "57231  To examine readiness of adolescents and young ...   \n",
      "57232  Intestinal epithelial cells exist in physiolog...   \n",
      "\n",
      "                                             Journal Language  Year  \\\n",
      "0                           Lancet (London, England)      eng  1980   \n",
      "1                           Lancet (London, England)      eng  1976   \n",
      "2                   Diseases of the colon and rectum      eng  1990   \n",
      "3                            British medical journal      eng  1972   \n",
      "4                            British medical journal      eng  1976   \n",
      "...                                              ...      ...   ...   \n",
      "57228                        NPJ Parkinson's disease      eng  2022   \n",
      "57229                          Crohn's & colitis 360      eng  2023   \n",
      "57230  ClinicoEconomics and outcomes research : CEOR      eng  2021   \n",
      "57231                      The Journal of pediatrics      eng  2023   \n",
      "57232                          Frontiers in genetics      eng  2021   \n",
      "\n",
      "                               DOI  \n",
      "0                           No DOI  \n",
      "1                           No DOI  \n",
      "2                           No DOI  \n",
      "3                           No DOI  \n",
      "4                           No DOI  \n",
      "...                            ...  \n",
      "57228   10.1038/s41531-022-00318-7  \n",
      "57229       10.1093/crocol/otad065  \n",
      "57230         10.2147/CEOR.S293698  \n",
      "57231  10.1016/j.jpeds.2023.113403  \n",
      "57232    10.3389/fgene.2021.791640  \n",
      "\n",
      "[57233 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame has been exported to /Users/xr/Desktop/Crohns_disease_abstract.csv\n"
     ]
    }
   ],
   "source": [
    "# 导出为CSV文件\n",
    "csv_file_path = '/Users/xr/Desktop/Crohns_disease_abstract.csv'\n",
    "df.to_csv(csv_file_path, index=False)\n",
    "print(f\"DataFrame has been exported to {csv_file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
